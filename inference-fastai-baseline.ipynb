{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13d16edb",
   "metadata": {
    "papermill": {
     "duration": 0.00628,
     "end_time": "2022-07-07T23:21:16.173574",
     "exception": false,
     "start_time": "2022-07-07T23:21:16.167294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "    <h1>[Inference] - FastAI Baseline</h1>\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a26cc3",
   "metadata": {
    "papermill": {
     "duration": 0.004943,
     "end_time": "2022-07-07T23:21:16.183936",
     "exception": false,
     "start_time": "2022-07-07T23:21:16.178993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "<img src=\"https://hubmapconsortium.org/wp-content/uploads/2019/01/HuBMAP-Retina-Logo-Color.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b3b786",
   "metadata": {
    "papermill": {
     "duration": 0.004866,
     "end_time": "2022-07-07T23:21:16.194205",
     "exception": false,
     "start_time": "2022-07-07T23:21:16.189339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description \n",
    "\n",
    "Welcome to Human BioMolecular Atlas Program (HuBMAP) + Human Protein Atlas (HPA) competition. \n",
    "The objective of this challenge is segmentation of functional tissue units (FTU. e.g., glomeruli in kidney or alveoli in the lung) in biopsy slides from several different organs. \n",
    "The underlying data includes imagery from different sources prepared with different protocols at a variety of resolutions, reflecting typical challenges for working with medical data.\n",
    "\n",
    "This notebook provides a fast.ai starter Pytorch code based on a U-shape network (UneXt50) that was used on multiple competitions in the past and includes several tricks from the previous segmentation competitions.\n",
    "It is [dividing the images into tiles](https://www.kaggle.com/code/thedevastator/converting-to-256x256), selection of tiles with tissue, evaluation of the predictions of multiple models with TTA, combining the tile masks back into image level masks, and conversion into RLE. The [inference](https://www.kaggle.com/code/thedevastator/inference-fastai-baseline) is performed based on models trained in the [fast.ai training notebook](https://www.kaggle.com/code/thedevastator/training-fastai-baseline).\n",
    "\n",
    "**Training & Dataset Creation**\n",
    "\n",
    "#### - Training Notebook [here](https://www.kaggle.com/code/thedevastator/training-fastai-baseline). \n",
    "#### - Dataset Creation [here](https://www.kaggle.com/code/thedevastator/converting-to-256x256). \n",
    "\n",
    "**Precomputed Datasets**\n",
    "\n",
    "##### - [Dataset (512 x 512)](https://www.kaggle.com/datasets/thedevastator/hubmap-2022-512x512/)\n",
    "\n",
    "##### - [Dataset (256 x 256)](https://www.kaggle.com/datasets/thedevastator/hubmap-2022-256x256/)\n",
    "\n",
    "##### - [Dataset (128 x 128)](https://www.kaggle.com/datasets/thedevastator/hubmap-2022-128x128/settings)\n",
    "\n",
    "____\n",
    "\n",
    "#### Everything is based on the excellent [notebooks](https://www.kaggle.com/code/iafoss/hubmap-pytorch-fast-ai-starter) by [iafoss](https://www.kaggle.com/iafoss) \n",
    "All credit to belongs to the original author!\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec622d6b",
   "metadata": {
    "papermill": {
     "duration": 0.004966,
     "end_time": "2022-07-07T23:21:16.204761",
     "exception": false,
     "start_time": "2022-07-07T23:21:16.199795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001ca4be",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-07-07T23:21:16.217473Z",
     "iopub.status.busy": "2022-07-07T23:21:16.216810Z",
     "iopub.status.idle": "2022-07-07T23:21:17.935067Z",
     "shell.execute_reply": "2022-07-07T23:21:17.934025Z"
    },
    "papermill": {
     "duration": 1.727712,
     "end_time": "2022-07-07T23:21:17.937605",
     "exception": false,
     "start_time": "2022-07-07T23:21:16.209893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lovasz-Softmax and Jaccard hinge loss in PyTorch\n",
    "Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "try:\n",
    "    from itertools import  ifilterfalse\n",
    "except ImportError: # py3k\n",
    "    from itertools import  filterfalse\n",
    "\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1: # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def iou_binary(preds, labels, EMPTY=1., ignore=None, per_image=True):\n",
    "    \"\"\"\n",
    "    IoU for foreground class\n",
    "    binary: 1 foreground, 0 background\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        intersection = ((label == 1) & (pred == 1)).sum()\n",
    "        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n",
    "        if not union:\n",
    "            iou = EMPTY\n",
    "        else:\n",
    "            iou = float(intersection) / union\n",
    "        ious.append(iou)\n",
    "    iou = f_mean(ious)    # mean accross images if per_image\n",
    "    return 100 * iou\n",
    "\n",
    "\n",
    "def iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\n",
    "    \"\"\"\n",
    "    Array of IoU for each (non ignored) class\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        iou = []    \n",
    "        for i in range(C):\n",
    "            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n",
    "                intersection = ((label == i) & (pred == i)).sum()\n",
    "                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n",
    "                if not union:\n",
    "                    iou.append(EMPTY)\n",
    "                else:\n",
    "                    iou.append(float(intersection) / union)\n",
    "        ious.append(iou)\n",
    "    ious = map(f_mean, zip(*ious)) # mean accross images if per_image\n",
    "    return 100 * np.array(ious)\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = f_mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n",
    "                          for log, lab in zip(logits, labels))\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return logits.sum() * 0.\n",
    "    signs = 2. * labels.float() - 1.\n",
    "    errors = (1. - logits * Variable(signs))\n",
    "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "    perm = perm.data\n",
    "    gt_sorted = labels[perm]\n",
    "    grad = lovasz_grad(gt_sorted)\n",
    "    #loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
    "    loss = torch.dot(F.elu(errors_sorted)+1, Variable(grad))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = scores.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = (labels != ignore)\n",
    "    vscores = scores[valid]\n",
    "    vlabels = labels[valid]\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "class StableBCELoss(torch.nn.modules.Module):\n",
    "    def __init__(self):\n",
    "         super(StableBCELoss, self).__init__()\n",
    "    def forward(self, input, target):\n",
    "         neg_abs = - input.abs()\n",
    "         loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
    "         return loss.mean()\n",
    "\n",
    "\n",
    "def binary_xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Cross entropy loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    logits, labels = flatten_binary_scores(logits, labels, ignore)\n",
    "    loss = StableBCELoss()(logits, Variable(labels.float()))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# --------------------------- MULTICLASS LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_softmax(probas, labels, only_present=False, per_image=False, ignore=None):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      only_present: average only on classes present in ground truth\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class labels\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = f_mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), only_present=only_present)\n",
    "                          for prob, lab in zip(probas, labels))\n",
    "    else:\n",
    "        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), only_present=only_present)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, only_present=False):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      only_present: average only on classes present in ground truth\n",
    "    \"\"\"\n",
    "    C = probas.size(1)\n",
    "    losses = []\n",
    "    for c in range(C):\n",
    "        fg = (labels == c).float() # foreground for class c\n",
    "        if only_present and fg.sum() == 0:\n",
    "            continue\n",
    "        errors = (Variable(fg) - probas[:, c]).abs()\n",
    "        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n",
    "        perm = perm.data\n",
    "        fg_sorted = fg[perm]\n",
    "        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n",
    "    return f_mean(losses)\n",
    "\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch\n",
    "    \"\"\"\n",
    "    B, C, H, W = probas.size()\n",
    "    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return probas, labels\n",
    "    valid = (labels != ignore)\n",
    "    vprobas = probas[valid.nonzero().squeeze()]\n",
    "    vlabels = labels[valid]\n",
    "    return vprobas, vlabels\n",
    "\n",
    "def xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Cross entropy loss\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(logits, Variable(labels), ignore_index=255)\n",
    "\n",
    "\n",
    "# --------------------------- HELPER FUNCTIONS ---------------------------\n",
    "\n",
    "def f_mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(np.isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise ValueError('Empty mean')\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1038ae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:21:17.950629Z",
     "iopub.status.busy": "2022-07-07T23:21:17.949484Z",
     "iopub.status.idle": "2022-07-07T23:21:24.383850Z",
     "shell.execute_reply": "2022-07-07T23:21:24.382681Z"
    },
    "papermill": {
     "duration": 6.443234,
     "end_time": "2022-07-07T23:21:24.386307",
     "exception": false,
     "start_time": "2022-07-07T23:21:17.943073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../input/pytorchtimm/pytorch-image-models/\")\n",
    "sys.path.append(\"../input/ensemble/Ensemble-Pytorch/\")\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02557f3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-07T23:21:24.398862Z",
     "iopub.status.busy": "2022-07-07T23:21:24.397990Z",
     "iopub.status.idle": "2022-07-07T23:21:25.671801Z",
     "shell.execute_reply": "2022-07-07T23:21:25.670819Z"
    },
    "papermill": {
     "duration": 1.282566,
     "end_time": "2022-07-07T23:21:25.674239",
     "exception": false,
     "start_time": "2022-07-07T23:21:24.391673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision.all import *\n",
    "from rasterio.windows import Window\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings; warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40d89d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:21:25.688464Z",
     "iopub.status.busy": "2022-07-07T23:21:25.686103Z",
     "iopub.status.idle": "2022-07-07T23:21:25.903771Z",
     "shell.execute_reply": "2022-07-07T23:21:25.902863Z"
    },
    "papermill": {
     "duration": 0.226387,
     "end_time": "2022-07-07T23:21:25.906161",
     "exception": false,
     "start_time": "2022-07-07T23:21:25.679774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs = 64\n",
    "sz = 256    # the size of tiles\n",
    "reduce = 4  # reduce the original images by 4 times\n",
    "TH = 0.225  # threshold for positive predictions\n",
    "DATA = '../input/hubmap-organ-segmentation/test_images/'\n",
    "MODELS = [f'../input/updated-models/model_{i}.pth' for i in range(4)]\n",
    "# MODELS = [f'../input/hubmap-models/hubmap_models/run_0/model_{i}.pth' for i in range(4)] + [f'../input/hubmap-models/hubmap_models/run_1/model_{i}.pth' for i in range(4)] + [f'../input/training-fastai-baseline/model_{i}.pth' for i in range(4)]\n",
    "df_sample = pd.read_csv('../input/hubmap-organ-segmentation/sample_submission.csv')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc0d41",
   "metadata": {
    "papermill": {
     "duration": 0.004869,
     "end_time": "2022-07-07T23:21:25.916267",
     "exception": false,
     "start_time": "2022-07-07T23:21:25.911398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5dc2240",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-07-07T23:21:25.928470Z",
     "iopub.status.busy": "2022-07-07T23:21:25.927659Z",
     "iopub.status.idle": "2022-07-07T23:21:25.939903Z",
     "shell.execute_reply": "2022-07-07T23:21:25.939019Z"
    },
    "papermill": {
     "duration": 0.020601,
     "end_time": "2022-07-07T23:21:25.941842",
     "exception": false,
     "start_time": "2022-07-07T23:21:25.921241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions to convert encoding to mask and mask to encoding\n",
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for m,enc in enumerate(encs):\n",
    "        if isinstance(enc,np.float) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1 + m\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2enc(mask, n=1):\n",
    "    pixels = mask.T.flatten()\n",
    "    encs = []\n",
    "    for i in range(1,n+1):\n",
    "        p = (pixels == i).astype(np.int8)\n",
    "        if p.sum() == 0: encs.append(np.nan)\n",
    "        else:\n",
    "            p = np.concatenate([[0], p, [0]])\n",
    "            runs = np.where(p[1:] != p[:-1])[0] + 1\n",
    "            runs[1::2] -= runs[::2]\n",
    "            encs.append(' '.join(str(x) for x in runs))\n",
    "    return encs\n",
    "\n",
    "#https://www.kaggle.com/bguberfain/memory-aware-rle-encoding\n",
    "#with transposed mask\n",
    "def rle_encode_less_memory(img):\n",
    "    #the image should be transposed\n",
    "    pixels = img.T.flatten()\n",
    "    \n",
    "    # This simplified method requires first and last pixel to be zero\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    \n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2ff8de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:21:25.954684Z",
     "iopub.status.busy": "2022-07-07T23:21:25.953313Z",
     "iopub.status.idle": "2022-07-07T23:21:25.974137Z",
     "shell.execute_reply": "2022-07-07T23:21:25.973295Z"
    },
    "papermill": {
     "duration": 0.028961,
     "end_time": "2022-07-07T23:21:25.976000",
     "exception": false,
     "start_time": "2022-07-07T23:21:25.947039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/thedevastator/hubmap-2022-256x256\n",
    "mean = np.array([0.7720342, 0.74582646, 0.76392896])\n",
    "std = np.array([0.24745085, 0.26182273, 0.25782376])\n",
    "\n",
    "s_th = 40  #saturation blancking threshold\n",
    "p_th = 1000*(sz//256)**2 #threshold for the minimum number of pixels\n",
    "identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "\n",
    "def img2tensor(img,dtype:np.dtype=np.float32):\n",
    "    if img.ndim==2 : img = np.expand_dims(img,2)\n",
    "    img = np.transpose(img,(2,0,1))\n",
    "    return torch.from_numpy(img.astype(dtype, copy=False))\n",
    "\n",
    "class HuBMAPDataset(Dataset):\n",
    "    def __init__(self, idx, sz=sz, reduce=reduce):\n",
    "        self.data = rasterio.open(os.path.join(DATA,idx+'.tiff'), transform = identity,\n",
    "                                 num_threads='all_cpus')\n",
    "        # some images have issues with their format \n",
    "        # and must be saved correctly before reading with rasterio\n",
    "        if self.data.count != 3:\n",
    "            subdatasets = self.data.subdatasets\n",
    "            self.layers = []\n",
    "            if len(subdatasets) > 0:\n",
    "                for i, subdataset in enumerate(subdatasets, 0):\n",
    "                    self.layers.append(rasterio.open(subdataset))\n",
    "        self.shape = self.data.shape\n",
    "        self.reduce = reduce\n",
    "        self.sz = reduce*sz\n",
    "        self.pad0 = (self.sz - self.shape[0]%self.sz)%self.sz\n",
    "        self.pad1 = (self.sz - self.shape[1]%self.sz)%self.sz\n",
    "        self.n0max = (self.shape[0] + self.pad0)//self.sz\n",
    "        self.n1max = (self.shape[1] + self.pad1)//self.sz\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n0max*self.n1max\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # the code below may be a little bit difficult to understand,\n",
    "        # but the thing it does is mapping the original image to\n",
    "        # tiles created with adding padding, as done in\n",
    "        # https://www.kaggle.com/iafoss/256x256-images ,\n",
    "        # and then the tiles are loaded with rasterio\n",
    "        # n0,n1 - are the x and y index of the tile (idx = n0*self.n1max + n1)\n",
    "        n0,n1 = idx//self.n1max, idx%self.n1max\n",
    "        # x0,y0 - are the coordinates of the lower left corner of the tile in the image\n",
    "        # negative numbers correspond to padding (which must not be loaded)\n",
    "        x0,y0 = -self.pad0//2 + n0*self.sz, -self.pad1//2 + n1*self.sz\n",
    "        # make sure that the region to read is within the image\n",
    "        p00,p01 = max(0,x0), min(x0+self.sz,self.shape[0])\n",
    "        p10,p11 = max(0,y0), min(y0+self.sz,self.shape[1])\n",
    "        img = np.zeros((self.sz,self.sz,3),np.uint8)\n",
    "        # mapping the loade region to the tile\n",
    "        if self.data.count == 3:\n",
    "            img[(p00-x0):(p01-x0),(p10-y0):(p11-y0)] = np.moveaxis(self.data.read([1,2,3],\n",
    "                window=Window.from_slices((p00,p01),(p10,p11))), 0, -1)\n",
    "        else:\n",
    "            for i,layer in enumerate(self.layers):\n",
    "                img[(p00-x0):(p01-x0),(p10-y0):(p11-y0),i] =\\\n",
    "                  layer.read(1,window=Window.from_slices((p00,p01),(p10,p11)))\n",
    "        \n",
    "        if self.reduce != 1:\n",
    "            img = cv2.resize(img,(self.sz//reduce,self.sz//reduce),\n",
    "                             interpolation = cv2.INTER_AREA)\n",
    "        #check for empty imges\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h,s,v = cv2.split(hsv)\n",
    "        if (s>s_th).sum() <= p_th or img.sum() <= p_th:\n",
    "            #images with -1 will be skipped\n",
    "            return img2tensor((img/255.0 - mean)/std), -1\n",
    "        else: return img2tensor((img/255.0 - mean)/std), idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e23c1728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:21:25.987489Z",
     "iopub.status.busy": "2022-07-07T23:21:25.987242Z",
     "iopub.status.idle": "2022-07-07T23:21:25.998768Z",
     "shell.execute_reply": "2022-07-07T23:21:25.997867Z"
    },
    "papermill": {
     "duration": 0.019684,
     "end_time": "2022-07-07T23:21:26.000893",
     "exception": false,
     "start_time": "2022-07-07T23:21:25.981209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#iterator like wrapper that returns predicted masks\n",
    "class Model_pred:\n",
    "    def __init__(self, models, dl, tta:bool=True, half:bool=False):\n",
    "        self.models = models\n",
    "        self.dl = dl\n",
    "        self.tta = tta\n",
    "        self.half = half\n",
    "        \n",
    "    def __iter__(self):\n",
    "        count=0\n",
    "        with torch.no_grad():\n",
    "            for x,y in iter(self.dl):\n",
    "                if ((y>=0).sum() > 0): #exclude empty images\n",
    "                    x = x[y>=0].to(device)\n",
    "                    y = y[y>=0]\n",
    "                    if self.half: x = x.half()\n",
    "                    py = None\n",
    "                    for model in self.models:\n",
    "                        p = model(x)\n",
    "                        p = torch.sigmoid(p).detach()\n",
    "                        if py is None: py = p\n",
    "                        else: py += p\n",
    "                    if self.tta:\n",
    "                        #x,y,xy flips as TTA\n",
    "                        flips = [[-1],[-2],[-2,-1]]\n",
    "                        for f in flips:\n",
    "                            xf = torch.flip(x,f)\n",
    "                            for model in self.models:\n",
    "                                p = model(xf)\n",
    "                                p = torch.flip(p,f)\n",
    "                                py += torch.sigmoid(p).detach()\n",
    "                        py /= (1+len(flips))        \n",
    "                    py /= len(self.models)\n",
    "\n",
    "                    py = F.upsample(py, scale_factor=reduce, mode=\"bilinear\")\n",
    "                    py = py.permute(0,2,3,1).float().cpu()\n",
    "                    \n",
    "                    batch_size = len(py)\n",
    "                    for i in range(batch_size):\n",
    "                        yield py[i],y[i]\n",
    "                        count += 1\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.dl.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b088f9f",
   "metadata": {
    "papermill": {
     "duration": 0.004776,
     "end_time": "2022-07-07T23:21:26.010626",
     "exception": false,
     "start_time": "2022-07-07T23:21:26.005850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b801baf9",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-07-07T23:21:26.022167Z",
     "iopub.status.busy": "2022-07-07T23:21:26.021885Z",
     "iopub.status.idle": "2022-07-07T23:21:26.047059Z",
     "shell.execute_reply": "2022-07-07T23:21:26.046097Z"
    },
    "papermill": {
     "duration": 0.033114,
     "end_time": "2022-07-07T23:21:26.048929",
     "exception": false,
     "start_time": "2022-07-07T23:21:26.015815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FPN(nn.Module):\n",
    "    def __init__(self, input_channels:list, output_channels:list):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Sequential(nn.Conv2d(in_ch, out_ch*2, kernel_size=3, padding=1),\n",
    "             nn.ReLU(inplace=True), nn.BatchNorm2d(out_ch*2),\n",
    "             nn.Conv2d(out_ch*2, out_ch, kernel_size=3, padding=1))\n",
    "            for in_ch, out_ch in zip(input_channels, output_channels)])\n",
    "        \n",
    "    def forward(self, xs:list, last_layer):\n",
    "        hcs = [F.interpolate(c(x),scale_factor=2**(len(self.convs)-i),mode='bilinear') \n",
    "               for i,(c,x) in enumerate(zip(self.convs, xs))]\n",
    "        hcs.append(last_layer)\n",
    "        return torch.cat(hcs, dim=1)\n",
    "\n",
    "class UnetBlock(Module):\n",
    "    def __init__(self, up_in_c:int, x_in_c:int, nf:int=None, blur:bool=False,\n",
    "                 self_attention:bool=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(x_in_c)\n",
    "        ni = up_in_c//2 + x_in_c\n",
    "        nf = nf if nf is not None else max(up_in_c//2,32)\n",
    "        self.conv1 = ConvLayer(ni, nf, norm_type=None, **kwargs)\n",
    "        self.conv2 = ConvLayer(nf, nf, norm_type=None,\n",
    "            xtra=SelfAttention(nf) if self_attention else None, **kwargs)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, up_in:Tensor, left_in:Tensor) -> Tensor:\n",
    "        s = left_in\n",
    "        up_out = self.shuf(up_in)\n",
    "        cat_x = self.relu(torch.cat([up_out, self.bn(s)], dim=1))\n",
    "        return self.conv2(self.conv1(cat_x))\n",
    "        \n",
    "class _ASPPModule(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size, padding, dilation, groups=1):\n",
    "        super().__init__()\n",
    "        self.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n",
    "                stride=1, padding=padding, dilation=dilation, bias=False, groups=groups)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.atrous_conv(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return self.relu(x)\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, inplanes=512, mid_c=256, dilations=[6, 12, 18, 24], out_c=None):\n",
    "        super().__init__()\n",
    "        self.aspps = [_ASPPModule(inplanes, mid_c, 1, padding=0, dilation=1)] + \\\n",
    "            [_ASPPModule(inplanes, mid_c, 3, padding=d, dilation=d,groups=4) for d in dilations]\n",
    "        self.aspps = nn.ModuleList(self.aspps)\n",
    "        self.global_pool = nn.Sequential(nn.AdaptiveMaxPool2d((1, 1)),\n",
    "                        nn.Conv2d(inplanes, mid_c, 1, stride=1, bias=False),\n",
    "                        nn.BatchNorm2d(mid_c), nn.ReLU())\n",
    "        out_c = out_c if out_c is not None else mid_c\n",
    "        self.out_conv = nn.Sequential(nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False),\n",
    "                                    nn.BatchNorm2d(out_c), nn.ReLU(inplace=True))\n",
    "        self.conv1 = nn.Conv2d(mid_c*(2+len(dilations)), out_c, 1, bias=False)\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.global_pool(x)\n",
    "        xs = [aspp(x) for aspp in self.aspps]\n",
    "        x0 = F.interpolate(x0, size=xs[0].size()[2:], mode='bilinear', align_corners=True)\n",
    "        x = torch.cat([x0] + xs, dim=1)\n",
    "        return self.out_conv(x)\n",
    "    \n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32f250d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:21:26.060399Z",
     "iopub.status.busy": "2022-07-07T23:21:26.060157Z",
     "iopub.status.idle": "2022-07-07T23:21:26.073731Z",
     "shell.execute_reply": "2022-07-07T23:21:26.072802Z"
    },
    "papermill": {
     "duration": 0.021578,
     "end_time": "2022-07-07T23:21:26.075663",
     "exception": false,
     "start_time": "2022-07-07T23:21:26.054085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import ResNet, Bottleneck\n",
    "class UneXt50(nn.Module):\n",
    "    def __init__(self, stride=1, **kwargs):\n",
    "        super().__init__()\n",
    "        #encoder\n",
    "#         m = ResNet(Bottleneck, [3, 4, 6, 3], groups=32, width_per_group=4)\n",
    "        m = timm.create_model('ssl_resnext101_32x16d', pretrained = False)\n",
    "#         m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models',\n",
    "#                           'ResNeXt-101 32x16d')\n",
    "        self.enc0 = nn.Sequential(m.conv1, m.bn1, nn.ReLU(inplace=True))\n",
    "        self.enc1 = nn.Sequential(nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1),\n",
    "                            m.layer1) #256\n",
    "        self.enc2 = m.layer2 #512\n",
    "        self.enc3 = m.layer3 #1024\n",
    "        self.enc4 = m.layer4 #2048\n",
    "        #aspp with customized dilatations\n",
    "        self.aspp = ASPP(2048,256,out_c=512,dilations=[stride*1,stride*2,stride*3,stride*4])\n",
    "        self.drop_aspp = nn.Dropout2d(0.5)\n",
    "        #decoder\n",
    "        self.dec4 = UnetBlock(512,1024,256)\n",
    "        self.dec3 = UnetBlock(256,512,128)\n",
    "        self.dec2 = UnetBlock(128,256,64)\n",
    "        self.dec1 = UnetBlock(64,64,32)\n",
    "        self.fpn = FPN([512,256,128,64],[16]*4)\n",
    "        self.drop = nn.Dropout2d(0.1)\n",
    "        self.final_conv = ConvLayer(32+16*4, 1, ks=1, norm_type=None, act_cls=None)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        enc0 = self.enc0(x)\n",
    "        enc1 = self.enc1(enc0)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        enc4 = self.enc4(enc3)\n",
    "        enc5 = self.aspp(enc4)\n",
    "        dec3 = self.dec4(self.drop_aspp(enc5),enc3)\n",
    "        dec2 = self.dec3(dec3,enc2)\n",
    "        dec1 = self.dec2(dec2,enc1)\n",
    "        dec0 = self.dec1(dec1,enc0)\n",
    "        x = self.fpn([enc5, dec3, dec2, dec1], dec0)\n",
    "        x = self.final_conv(self.drop(x))\n",
    "        x = F.interpolate(x,scale_factor=2,mode='bilinear')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "767b7cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:21:26.087297Z",
     "iopub.status.busy": "2022-07-07T23:21:26.086562Z",
     "iopub.status.idle": "2022-07-07T23:22:08.327634Z",
     "shell.execute_reply": "2022-07-07T23:22:08.326615Z"
    },
    "papermill": {
     "duration": 42.249721,
     "end_time": "2022-07-07T23:22:08.330356",
     "exception": false,
     "start_time": "2022-07-07T23:21:26.080635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "for path in MODELS:\n",
    "    state_dict = torch.load(path,map_location=torch.device('cpu'))\n",
    "    model = UneXt50()\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.float()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    models.append(model)\n",
    "\n",
    "del state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e7f75",
   "metadata": {
    "papermill": {
     "duration": 0.004971,
     "end_time": "2022-07-07T23:22:08.340915",
     "exception": false,
     "start_time": "2022-07-07T23:22:08.335944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4153f5",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-07-07T23:22:08.352426Z",
     "iopub.status.busy": "2022-07-07T23:22:08.352111Z",
     "iopub.status.idle": "2022-07-07T23:22:18.176296Z",
     "shell.execute_reply": "2022-07-07T23:22:18.174747Z"
    },
    "papermill": {
     "duration": 9.832856,
     "end_time": "2022-07-07T23:22:18.178893",
     "exception": false,
     "start_time": "2022-07-07T23:22:08.346037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.81s/it]\n"
     ]
    }
   ],
   "source": [
    "names,preds = [],[]\n",
    "for idx,row in tqdm(df_sample.iterrows(),total=len(df_sample)):\n",
    "    idx = str(row['id'])\n",
    "    ds = HuBMAPDataset(idx)\n",
    "    #rasterio cannot be used with multiple workers\n",
    "    dl = DataLoader(ds,bs,num_workers=0,shuffle=False,pin_memory=True)\n",
    "    mp = Model_pred(models,dl)\n",
    "    #generate masks\n",
    "    mask = torch.zeros(len(ds),ds.sz,ds.sz,dtype=torch.int8)\n",
    "    for p,i in iter(mp): mask[i.item()] = p.squeeze(-1) > TH\n",
    "    \n",
    "    #reshape tiled masks into a single mask and crop padding\n",
    "    mask = mask.view(ds.n0max,ds.n1max,ds.sz,ds.sz).\\\n",
    "        permute(0,2,1,3).reshape(ds.n0max*ds.sz,ds.n1max*ds.sz)\n",
    "    mask = mask[ds.pad0//2:-(ds.pad0-ds.pad0//2) if ds.pad0 > 0 else ds.n0max*ds.sz,\n",
    "        ds.pad1//2:-(ds.pad1-ds.pad1//2) if ds.pad1 > 0 else ds.n1max*ds.sz]\n",
    "    \n",
    "    #convert to rle\n",
    "    #https://www.kaggle.com/bguberfain/memory-aware-rle-encoding\n",
    "    rle = rle_encode_less_memory(mask.numpy())\n",
    "    names.append(idx)\n",
    "    preds.append(rle)\n",
    "    del mask, ds, dl\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eae9646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:22:18.192091Z",
     "iopub.status.busy": "2022-07-07T23:22:18.191788Z",
     "iopub.status.idle": "2022-07-07T23:22:18.199628Z",
     "shell.execute_reply": "2022-07-07T23:22:18.198770Z"
    },
    "papermill": {
     "duration": 0.016107,
     "end_time": "2022-07-07T23:22:18.201608",
     "exception": false,
     "start_time": "2022-07-07T23:22:18.185501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':names,'rle':preds})\n",
    "df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5b60cf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-07T23:22:18.213251Z",
     "iopub.status.busy": "2022-07-07T23:22:18.213001Z",
     "iopub.status.idle": "2022-07-07T23:22:18.226802Z",
     "shell.execute_reply": "2022-07-07T23:22:18.225129Z"
    },
    "papermill": {
     "duration": 0.021812,
     "end_time": "2022-07-07T23:22:18.228684",
     "exception": false,
     "start_time": "2022-07-07T23:22:18.206872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10078</td>\n",
       "      <td>2047822 467 2049845 467 2051868 467 2053893 465 2055918 463 2057943 461 2059968 459 2061994 456 2064018 455 2066043 453 2068067 452 2070092 450 2072116 449 2074140 448 2076165 446 2078189 445 2080213 444 2082237 443 2084262 441 2086286 440 2088310 439 2090334 438 2092359 436 2094383 435 2096408 433 2098432 432 2100457 430 2102480 430 2104504 429 2106528 428 2108551 428 2110574 428 2112597 428 2114620 428 2116643 428 2118666 428 2120689 428 2122712 428 2124735 428 2126758 428 2128781 428 2130804 428 2132827 428 2134851 427 2136874 427 2138897 427 2140921 426 2142944 426 2144968 425 2146992 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  \\\n",
       "0  10078   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       rle  \n",
       "0  2047822 467 2049845 467 2051868 467 2053893 465 2055918 463 2057943 461 2059968 459 2061994 456 2064018 455 2066043 453 2068067 452 2070092 450 2072116 449 2074140 448 2076165 446 2078189 445 2080213 444 2082237 443 2084262 441 2086286 440 2088310 439 2090334 438 2092359 436 2094383 435 2096408 433 2098432 432 2100457 430 2102480 430 2104504 429 2106528 428 2108551 428 2110574 428 2112597 428 2114620 428 2116643 428 2118666 428 2120689 428 2122712 428 2124735 428 2126758 428 2128781 428 2130804 428 2132827 428 2134851 427 2136874 427 2138897 427 2140921 426 2142944 426 2144968 425 2146992 ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b59a5",
   "metadata": {
    "papermill": {
     "duration": 0.005361,
     "end_time": "2022-07-07T23:22:18.240077",
     "exception": false,
     "start_time": "2022-07-07T23:22:18.234716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 73.558673,
   "end_time": "2022-07-07T23:22:21.288419",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-07T23:21:07.729746",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
